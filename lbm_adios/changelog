# Change Log
All notable changes to this project will be documented in this file.
The format is based on [Keep a Changelog](http://keepachangelog.com/) 
and this project adheres to [Semantic Versioning](http://semver.org/).

## [0.2.1] May 1 2017
#### changed
#### working version
	no gdim_define in code
	with 2 dimensions in jobfile
	seems reading takes sometime


## [0.2.0] April 28 2017
#### moved back to bridges
#### changes
#### note
	all timer in a job should be average

## [0.1.21] April 25 2017
#### Qestion:
	how to deal with different nlines in various processes?
	erase the warning flags?
	PMI error comes from number of arguments!
	-g option ?
	mpirun_rsh problem?(apply to ds_exmaple, see what happens)
		~/ds_examples/ex1_putget correct executed for 1:1
#### changes
	malloc-free in in the loop of raw_dspaces_read
	consumer need to know how many procs in producer
#### issues
	raw dspaces has rpc_connect error:9036590/results/consumer.log
#### trials
	run ds_examples/: works
	add -g flag, see output(need to roll back), same problem
	1:1 mpiio works, but very slow 5s per step writing time
	in bridges, writting time for 1:1 is much smaller:less .3s
	/pylon5/cc4s86p/fli5/data_broker_adios/1019183/results/producer.log
#### this PMI error happened before (Mar 30), then project was immigrated to
bridges

## [0.1.20] April 24 2017
#### changed
- project moved to comet
- flexpath configured
- in ADIOS removed the -g option, rebuilt
- do I need remove -g option in all libraries?
#### problems
- in comet, dataspaces nokeep has PMI error, 9024518
- in bridges, dspaces only one step, 103192, new: 1032015: move back to
'5bf287a81', try again
#### added
- raw dspaces added


-----------------------------------------------------------------------
moved on comet on April 24
## [0.1.19] 2017 April 24
#### added
	breakdown-timer in consumer side
#### Question
	adios_perform reads, use nonblock instead?


## [0.1.18] 2017 April 21
#### trials
- ADIOS_LOCKMODE_NONE doesn't work for dataspaces
#### to do
- flexpath use lock-non?
	no effect
- use lock-non but increase queue size to 100
---- better writting time, but longer gap between simulation stops and
analysis finishes(90s)
rank 0, t_prepare:0.096157 s, t_cal 74.112131 s,t_buffer = 0.378756, t_write 18.409973 s

## [0.1.17] 2017 April 20
#### Questions
	mpiio-io write when does it return?
		write into buffer then return immediately?
#### 2v1
		mpiio	flexpath	dataspaces	dimes
		41.84	48.276		148.33		
#### fixed
		dataspaces configuration
		DS_LIMIT should be timed with nprocs_producer
#### trying(need to roll back)
	2v2 blocked in second step
	add buffer size and group size back, job pending(1022958)
	still  same
	change lockmode to ADIOS_LOCKMODE_NONE
	

## [0.1.16] 2017 April 19
#### using producer:consumer= 1:1
	writing time 0.1s for each step(instead of 1.x s for 8vs4)
	writing time for 100 timesteps
		mpiio	flexpath	dataspaces	dimes
		35.61s	13.14s		59.30s		59.11s


## [0.1.15] 2017 April 18
#### changes
	remove get_group_size
	remov buffer max-size

## [0.1.14] 2017 April 17
#### buffersizese
buffersize for each process or nodes or global size?
is the reason that the first write takes more time?
group_size is nozero, if using staging, total_size is zero

#### removed the barrier in 


## [0.1.13] 2017 April 11
#### use flexpath 
-flexpath
	longer calculation time?
	t_prepare:0.099268 s, t_cal 42.772855 s,t_buffer = 0.388137, t_write 149.501805 s


## [0.1.12] 2017 April 6
#### Q
- what if only has dspaces write?
- is the fist step has the smallest writting time?
	989971
- cannot run producer without consumer
	989835
	

## [0.1.11] 2017 April 4 #### upon submission
- maxversion =5
- analysis is commented
#### try
- use larger buffer size in adios
	buffer size increased to 100M, no effect
- get analysis time
	stat:time for read 53.557231 s; time for advancing step 76.971237 s; time for analyst 39.008861 s

- use more servers
	same nodes, use 4 procs for server will reduce writting time from 150s to
	120s
	two nodes, with 4 procs, 114s
- doubts
	if disable analysis, why writting time is decreased?(985141& 989763)
	

#### MPIIO more tests


## [0.1.10] 2017 April 3
#### change
- extract the common part in job files
- results of 8vs4 is completed 
#### issues
- mpiio is faster then dspaces
- reason: 
	dspaces operation is strictly synchronized(cannot start next iteration if
	previous data is not consumered)
- analysis:
	is each transport method blocking or unblocking?
- break down the time
- blocking writes?
	disable analysis
	
## [0.1.9] 2017 April 2
#### change
- mpiio version lock fixed
- use scratch dir as working dir
## [0.1.8] 2017 Mar 31
#### change
- use -O3 now sim-only can finish 100 steps in 33.6s
- add error checking for adios init
- add has_more flag to indicate when producer finishes
## [0.1.7] 2017 Mar 30
#### done
- moved to bridges, correctly run with seprated nodes 
- tested 8v4
### to do
- test 48v24

## [0.1.6] 2017 Mar 29
#### added
- now run in separate nodes, but PMI erroj
## [0.1.5] 2017 mar 28
#### issues
- run job, but output not output to corresponding folder
kjjjj

## [0.1.4] 2017 Mar 27
#### added
- timer added in the begining of first simulation and at the end of last step
of analysis
- starting experiment in comet of staging method
- now different configurations are generated in different builds
- now all scripts are in scripts/(simulation_only version added)


## [0.1.3] 2017 mar 26
#### modified
- save errno of streaming read, so receiver will stop correctly
- add parameter 'mode' to insert_into_adios(), for keep, "a"(append) mode will
be used(first iteration use "w" to creat the file)
be used

#### added
- xml files are splited for different transport methods in xmls dir
- run_lbm will select different xml based on preprocessor

## [0.1.2] 2017 mar 25
#### fixed
mpiio need to use scratch path explicitly
#### Notes:
- for mppio:
	1. use scratch path explicitly for adios variable
	2. buffer size in xml should be larger than groupsize
	3. for a application with both MPI-io and staging read, init_read_method
	first than init_adios
#### changed
add kep using mpiio, now new ads_adaptor.c/h is created
## [0.1.1] 2017 Mar 24
#### Notes
- most data generated by lbm is 0
- testes 1 proc, correct
#### ADD
- add analysis component

## [0.1.0] 2017 Mar 23
#### Changed
- removed blocks, now each process need to prepare contiguous buffer for adios
#### To do
- use small size, verify the correctness of data read

