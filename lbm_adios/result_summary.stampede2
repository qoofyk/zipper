## Dec 9
    ~/Workspaces/LaucherTest/launcher_simple.job
## Dec 8
    497798
        use sim_only for 2176v1088, see memory usage
    497792
        sim_only 68v34
 try 68 v34: why use so much memory
        flexpath_version =10    
    496665
        2176v1088, with queue_size=10
        producer crash at step 10
    496657
        increase (back)the walltime to 20  mins, more steps use more memory?
                not, 2176 crash in the beginnnig
    496621
        nstop=100 again, now the queue size seems useful, consumer is after 10 steps
        54G 50 steps.
    496593, 496581 
        nstops=10, no memory usage shown
    496555
        nstops=100
            46G
## Dec 7
JOBS 
    496520
        print the dims
    496474
        use LOCK_MODE_CURRENT
        read_open_timeout changed to -1
        read side num_of_lines corrupted
            grep 'count':
                count:( 16954728007073792, 2)
    494391

    494380
        lock mode all
        queeu_size 1
    494187
        1088 again with -lm
        sim start3223, sim stop 3415, con stop: 3927
    494003
    flexpath 1088v544, 96G memory, same as 342994
        700s+, not linked with -m
    494049
        2096v1088


## Nov 27
JOBS
    460462
        use minimal dspaces configurations
## Nov 13
JOBS 
   424429
    move all applications in one node
   424386
    reproduce the dspaces problem in normal queue
    
    
## Oct 26
    flexpath queue_size?
   494330
    change queueu size to 1
        
   165316
       in normal queue, still rdma binding erro
       
	361833
	rerun flexpath with 2176vs1088 with LBM
		consumer malloc failed.
    xml interger?

## Oct 17
JOBS
    344553
    traces

## Oct 19
    355964
        16v8 with trace
## Oct 16
JOBS
-------------------------------------------------------
    343476
        343476, using 2 node for 8 server with 16vs8, erro
    343471
        8vs4 ok
    343468
        16vs8 err
    343466
        24vs12 native dspaces, err

    342994
        2176vs1088 again
    342100
        rerun
    342042
        flexpath with IMPI  respect placement, flexpath error, remove this
    272vs136 544vs272 are running together, should run applications separatedly
flexpath experiments
    340403
        flexpath 136vs68 with ib0 impi
    
    flexpath with greg's suggestion
    
    stick with socket+ib0
--------------------------------------------------------
retry libfabric
    34175
        memory corruption in fabric, not portable enough

    340164
        remove interface=ib0
        still with blocking
    340154
        with impi, rerun transport=ib and interface=ib0
            CMSelect blocking select


------------------------------------
    those are using mvapich, i should use impi!
    rerun CM_INTERFACE=ib0 with 272vs136
    340130
        use CMTransport=fabric with libfabric library, memory corruption ; use CM_INTERFACE=ib0, segmentation fault..
    340013
        use CM_INTERFACE=ib0, rerun 68vs34, faster then default, 542s for 68vs34
    340000
        CM_INTERFACE=ib0
        works!

## Oct 13
    333392
        68vs34, ib, cannot start

    333397
        68vs34, this is using fabric, back to socket
-----------------------------------------
    332778
        8vs4 with CM_NETWORK=ib0
    332636
        CMTransport=nonsense
        can detect
    332609
        CMTransport=ib
        now sockets seem load ib module
    332595
        CMTransport=nnti
        cm nnti not found back to default

   332667
        CMTransport=fabric
        cannot find library
        error is libpsm_infinipath.so.1: cannot open shared object file: No such file or directory

--------------------------------------------
        
   332067
        flexpath with verbose info
## Oct 12
tweak tranport
    332740
        fabric, 
    332743
        ib
experiment
    328792
        flexpath with 272vs136, stopped at step 97, see consumer_32.clog
    328263
        use stripe size=-1, and rerun 68vs34 mpiio
JOBS
    327488
        development queue with env variables in env_dev.log
    327475
        normal queue with envriables output in env_normal.log
## Oct 11
JOBS
    use idev interactive session:
        *. dev queue
            1. run the server with
                mpiexec.hydra  -n 4 /work/04446/tg837458/stampede2/envs/Dataspacesroot/bin/dataspaces_server -s 4 -c 48 &> results/dev_server.log &
            2. run writer with
                mpiexec.hydra  -n 32 /work/04446/tg837458/stampede2/envs/Dataspacesroot/bin/test_writer DATASPACES 32 3 2 4 4 128 64 64 10 1 &> results/dev_writer.log  &
            3. run the reader with
                mpiexec.hydra  -n 16 /work/04446/tg837458/stampede2/envs/Dataspacesroot/bin/test_reader DATASPACES 16  3 2 2 4 128 128 64 10 2 &> results/dev_reader.log &
        * compute queue, run the server with 
            mpiexec.hydra  -n 4 /work/04446/tg837458/stampede2/envs/Dataspacesroot/bin/dataspaces_server -s 4 -c 48 &> results/compute_server.log &
                rdma_bind_addr error imediately 

    324279:
       development queue with output ldd info
    324337:
        normal queue with output ldd info
    
## Oct 10
# conclusion
    1. rpc_bind_addr always happens in normal queue
    2. 
continue address the normal queue
    321133
        ds-test-tense with 8 nodes, each with 64 procs, normal, rdma_bind_addr err in server!
    321122
        ds-test-tense with 8 nodes, each with 64 procs, rpc_connect error, development
   

NOTE: same  scripts of ds-test.skel, sometimes with rpc_connect erro
    321035
        development with 3 nodes, 
    320983
        development queue, fine
    320997
        normal queue, rdma err
## Oct 8
JOBS libfabrics

    318997
        flexpath, slower than disk!!
    
    318996
        mpiio
    ------------------------------------------------
    above has 512/256, see google doc for more details

	318948
		flexpath 196
	318892
		flexpath now use same adios_staging with dspaces
		correct

    
## Oct 6
JOBS
    311613
        development queue can run

    311586
        normal queue cannot run

    using impi again
    --------------------------------------
    311147
    dataspaces shipped test program, with 8 server nodes, rdma_bind_addr
    310980
    run native-adios 196 with mvapich dspaces built, still has rdma_bind_addr
    
    310961
    using mvapich in stampded with with-infiband-interface=ib0
        app cp is full.
        'dsrpc_cn_register()' failed with -12.
    * solved: add DATASPACES as an auument

## Oct 5
JOBS
    310262
        196vs98 with native_dspace, rdma_bind_addr err
    310256
        8vs4 with native_dspaces

    above starts using new lanucher with machinefile
    --------------------------------
    
    309374
        8vs4 with mpiio
        correctly run
    
    
    309206
        196vs98 dspaces_nokeep
        server cannot init:
            rdma_bind_addr -1 in rpc_server_init.
            'rpc_server_init()': failed with -1.

    309158
        8vs4 dspaces_nokeep
        use new machinefile layout
    
    308648
        196vs98
        process layout
        server procs(28*4 procs are packed into two nodes)
## Oct 2
JOBS
    303418 native staging  196vs 98, rpc bind err

    303396 adios_staging of dspaces works
    303356 native_staging of dpsaces, works
    303350 mpiio successfully run, works

